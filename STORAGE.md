# Storage Management Guide

This document details how persistent storage is managed in the Kubernetes cluster using the local-path provisioner, including the custom path configuration.

## Overview

The cluster uses [local-path-provisioner](https://github.com/rancher/local-path-provisioner) for persistent storage, configured to store data in `/mnt/storage` on the host node. This allows for straightforward backups and management of persistent data outside of Kubernetes.

## Configuration

The local-path provisioner is configured through a ConfigMap that defines where and how persistent volumes are created on the host.

### Current Configuration

The configuration is defined in `k8s/local-path-config.yaml`:

```yaml
apiVersion: v1
data:
  config.json: |-
    {
      "nodePathMap":[
      {
        "node":"DEFAULT_PATH_FOR_NON_LISTED_NODES",
        "paths":["/mnt/storage"]
      }
      ]
    }
  # ... other configuration ...
kind: ConfigMap
metadata:
  name: local-path-config
  namespace: kube-system
```

This configuration specifies that all persistent volumes will be created under `/mnt/storage` on the host node.

## Applying the Configuration

To apply or update the storage configuration:

```bash
kubectl apply -f k8s/local-path-config.yaml
```

## PersistentVolumeClaims in the Cluster

The following PersistentVolumeClaims are defined in the cluster:

| Service | PVC Name | Size | Path on Host |
|---------|----------|------|-------------|
| Home Assistant | ha-config-pvc | 12Gi | `/mnt/storage/ha-config-pvc-xxx` |
| ESPHome | esphome-config-pvc | 4Gi | `/mnt/storage/esphome-config-pvc-xxx` |
| Pi-hole | pihole-etc-pvc | 1Gi | `/mnt/storage/pihole-etc-pvc-xxx` |
| Pi-hole | dnsmasq-etc-pvc | 8Gi | `/mnt/storage/dnsmasq-etc-pvc-xxx` |
| WireGuard | wireguard-data-pvc | 4Gi | `/mnt/storage/wireguard-data-pvc-xxx` |
| Backrest | backrest-data-pvc | 24Gi | `/mnt/storage/backrest-data-pvc-xxx` |

The exact path includes a unique suffix generated by Kubernetes.

## Manual Volume Management

### Preparing the Host

Ensure the main storage directory exists on the host:

```bash
sudo mkdir -p /mnt/storage
sudo chmod 755 /mnt/storage
```

### Backing Up Volumes

To back up all persistent volumes:

```bash
sudo rsync -av /mnt/storage/ /path/to/backup/storage/
```

For individual services:

```bash
# Example for Home Assistant
sudo rsync -av /mnt/storage/ha-config-pvc-xxx/ /path/to/backup/homeassistant/
```

### Restoring Volumes

To restore data to a volume:

```bash
sudo rsync -av /path/to/backup/homeassistant/ /mnt/storage/ha-config-pvc-xxx/
```

After restoring, you may need to restart the pods to apply changes:

```bash
kubectl rollout restart deployment homeassistant -n domotica
```

## Expanding Storage

To increase the size of a PersistentVolumeClaim:

1. Edit the PVC manifest (e.g., `k8s/base/domotica/homeassistant/pvc.yaml`)
2. Update the storage request value
3. Apply the change:

```bash
kubectl apply -f k8s/base/domotica/homeassistant/pvc.yaml
```

Note: Expanding PVCs may require the StorageClass to support volume expansion.

## Monitoring Storage Usage

Check the used space on persistent volumes:

```bash
# On the host node
df -h /mnt/storage/*

# Or from inside a pod
kubectl exec -it <pod-name> -n <namespace> -- df -h /config
```

## Troubleshooting

### Permission Issues

If containers can't write to volumes:

```bash
# Ensure proper ownership on the host
sudo chown -R 1000:1000 /mnt/storage/volume-path-xxx/
```

Different applications may require different user IDs.

### Volume Mount Failures

If volumes fail to mount:

```bash
# Check the PersistentVolume status
kubectl get pv

# Check PersistentVolumeClaim status
kubectl get pvc -A

# Check events related to PVCs
kubectl describe pvc <pvc-name> -n <namespace>
```

## Additional Storage Classes

While this cluster primarily uses local-path storage, you can add other storage classes like NFS:

```yaml
apiVersion: storage.k8s.io/v1
kind: StorageClass
metadata:
  name: nfs-storage
provisioner: kubernetes.io/nfs
parameters:
  server: <nfs-server-ip>
  path: /exported/path
```

Apply with:

```bash
kubectl apply -f nfs-storage-class.yaml
```

## Migrating Data Between Volumes

To migrate data from one volume to another:

1. Create a temporary pod with both volumes mounted:

```yaml
apiVersion: v1
kind: Pod
metadata:
  name: volume-migration
  namespace: default
spec:
  containers:
  - name: volume-mover
    image: busybox
    command: ["sleep", "3600"]
    volumeMounts:
    - name: source-volume
      mountPath: /source
    - name: target-volume
      mountPath: /target
  volumes:
  - name: source-volume
    persistentVolumeClaim:
      claimName: source-pvc
  - name: target-volume
    persistentVolumeClaim:
      claimName: target-pvc
```

2. Copy the data:

```bash
kubectl exec -it volume-migration -- cp -av /source/* /target/
```

3. Delete the temporary pod:

```bash
kubectl delete pod volume-migration
```